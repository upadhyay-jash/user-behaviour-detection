# -*- coding: utf-8 -*-
"""ML_PROJECT-SEM6.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10AlhsU2crp5RQewIAnd5RNuPklP-AG08
"""

# --- Import Libraries ---
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score, recall_score, f1_score, classification_report, confusion_matrix

from imblearn.over_sampling import SMOTE

# --- Load Dataset ---
file_path = "/content/user_behavior_dataset.csv"  # Replace with your path
df = pd.read_csv(file_path)

# --- Drop Useless Columns ---
df = df.drop(columns=["User ID"])

# --- Encode Categorical Columns ---
label_encoders = {}
for col in ["Device Model", "Operating System", "Gender"]:
    le = LabelEncoder()
    df[col] = le.fit_transform(df[col])
    label_encoders[col] = le

# --- Define Features & Target ---
X = df.drop(columns=["User Behavior Class"])
y = df["User Behavior Class"]

# --- Normalize Features ---
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# --- Split Dataset ---
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)

# --- Apply SMOTE if Needed ---
print("Class Distribution Before SMOTE:\n", y_train.value_counts())
if y_train.value_counts().min() / y_train.value_counts().max() < 0.5:
    print("Applying SMOTE to balance dataset...\n")
    smote = SMOTE()
    X_train, y_train = smote.fit_resample(X_train, y_train)

# --- Initialize Models ---
models = {
    "Random Forest": RandomForestClassifier(n_estimators=100, random_state=42),
    "Logistic Regression": LogisticRegression(max_iter=1000),
    "SVM": SVC(kernel="linear", C=1.0),
    "KNN": KNeighborsClassifier(n_neighbors=5),
}

# --- Train, Evaluate, and Cross-Validate Models ---
results = {}

for name, model in models.items():
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)

    acc = accuracy_score(y_test, y_pred)
    recall = recall_score(y_test, y_pred, average='weighted')
    f1 = f1_score(y_test, y_pred, average='weighted')
    cv_score = cross_val_score(model, X_scaled, y, cv=5, scoring='accuracy').mean()

    results[name] = {
        'Accuracy': acc,
        'Recall': recall,
        'F1 Score': f1,
        'CV Accuracy': cv_score
    }

    print(f"\n{name} Model")
    print("-" * 30)
    print("Accuracy    :", acc)
    print("Recall      :", recall)
    print("F1 Score    :", f1)
    print("CV Accuracy :", cv_score)
    print("Classification Report:\n", classification_report(y_test, y_pred))

    # Confusion Matrix Plot
    cm = confusion_matrix(y_test, y_pred)
    plt.figure(figsize=(6, 4))
    sns.heatmap(cm, annot=True, fmt="d", cmap="Blues",
                xticklabels=np.unique(y), yticklabels=np.unique(y))
    plt.title(f"Confusion Matrix - {name}")
    plt.xlabel("Predicted")
    plt.ylabel("Actual")
    plt.show()

# --- Show All Model Results in Table ---
results_df = pd.DataFrame(results).T
print("\nModel Performance Comparison:\n")
print(results_df)

# --- Feature Importance for Random Forest ---
rf_model = models["Random Forest"]
importances = rf_model.feature_importances_
feature_names = X.columns

plt.figure(figsize=(10, 5))
sns.barplot(x=importances, y=feature_names, palette="coolwarm")
plt.title("Feature Importance - Random Forest")
plt.xlabel("Importance")
plt.ylabel("Feature")
plt.show()

# --- Coefficients for Logistic Regression ---
lr_model = models["Logistic Regression"]
coefficients = lr_model.coef_[0]

plt.figure(figsize=(10, 5))
sns.barplot(x=coefficients, y=feature_names, palette="coolwarm")
plt.title("Feature Coefficients - Logistic Regression")
plt.xlabel("Coefficient Value")
plt.ylabel("Feature")
plt.show()

# --- Store training feature names ---
feature_names = X.columns.tolist()

# --- Define Unseen Data (only partial columns) ---
unseen_data = {
    "Device Model": ["Samsung S21", "iPhone 13", "OnePlus 9"],
    "Operating System": ["Android", "iOS", "Android"],
    "Gender": ["Male", "Female", "Male"],
    "Session Duration (min)": [12, 25, 18],
    "Clicks": [22, 40, 35]
}
unseen_df = pd.DataFrame(unseen_data)

# --- Fill missing columns used in training ---
for col in feature_names:
    if col not in unseen_df.columns:
        unseen_df[col] = 0  # Default or median can be used

# --- Drop extra columns not in training ---
unseen_df = unseen_df[feature_names]

# --- Encode categorical columns ---
for col in ["Device Model", "Operating System", "Gender"]:
    le = label_encoders[col]
    unseen_df[col] = unseen_df[col].apply(lambda x: le.transform([x])[0] if x in le.classes_ else -1)

# --- Normalize unseen data ---
unseen_scaled = scaler.transform(unseen_df)

# --- Predict ---
print("\nPredictions on Unseen Data:")
for name, model in models.items():
    preds = model.predict(unseen_scaled)
    print(f"{name} Predictions: {preds}")

from sklearn.model_selection import KFold, StratifiedKFold, LeaveOneOut, cross_val_score

# --- Cross Validation Techniques ---

for name, model in models.items():
    print(f"\nCross Validation Results for {name}")
    print("-" * 40)

    # K-Fold
    kf = KFold(n_splits=5, shuffle=True, random_state=42)
    kf_scores = cross_val_score(model, X_scaled, y, cv=kf)
    print(f"K-Fold CV Scores: {kf_scores}")
    print(f"K-Fold CV Mean Accuracy: {np.mean(kf_scores)}")

    # Stratified K-Fold
    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
    skf_scores = cross_val_score(model, X_scaled, y, cv=skf)
    print(f"Stratified K-Fold CV Scores: {skf_scores}")
    print(f"Stratified K-Fold Mean Accuracy: {np.mean(skf_scores)}")

    # Leave-One-Out
    loo = LeaveOneOut()
    loo_scores = cross_val_score(model, X_scaled, y, cv=loo)
    print(f"Leave-One-Out CV Mean Accuracy: {np.mean(loo_scores)}")